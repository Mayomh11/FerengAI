{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shhhhhhh......\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# Other imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from mongoDB\n",
    "import pymongo\n",
    "import ezmongo\n",
    "df = ezmongo.get_data(\"MSFT\",\"cleaned_trained_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I solating the columns we want.\n",
    "# Lets try all data points\n",
    "input_df = df.drop(['Date','BuyOrSell'], axis=1)\n",
    "\n",
    "output_df = df['BuyOrSell'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "# Even though the last columns is already 1 or 0, to_categorical needs to somehow convert this into \n",
    "# an array that looks like [x1,x2] and literally separate them into different states\n",
    "# Try printing out output and outputs_df to see the difference.\n",
    "output_hot_shot_encoded = to_categorical(output_df)\n",
    "\n",
    "#Creating the NN. Import the stuff\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT THIS SECTION OF CODE TO DESIGN YOUR OWN NEURAL NET.\n",
    "\n",
    "#Create the model\n",
    "model = Sequential()\n",
    "\n",
    "#Setting general NN info here\n",
    "\n",
    "number_of_inputs = len(input_df.columns)\n",
    "\n",
    "number_of_layers = number_of_inputs + 10\n",
    "\n",
    "number_of_neurons_per_layer = number_of_layers + 10\n",
    "\n",
    "\n",
    "#Adding the first input layer\n",
    "model.add(Dense(units=number_of_neurons_per_layer, activation='relu', input_dim=number_of_inputs))\n",
    "\n",
    "for i in range(number_of_layers):\n",
    "    model.add(Dense(units=number_of_neurons_per_layer, activation='relu'))\n",
    "\n",
    "#Adding the output layer\n",
    "model.add(Dense(units=2, activation='softmax')) \n",
    "#Compiling\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8398/8398 - 2s - loss: 0.6910 - acc: 0.5376\n",
      "Epoch 2/1000\n",
      "8398/8398 - 1s - loss: 0.6908 - acc: 0.5381\n",
      "Epoch 3/1000\n",
      "8398/8398 - 2s - loss: 0.6899 - acc: 0.5381\n",
      "Epoch 4/1000\n",
      "8398/8398 - 1s - loss: 0.6902 - acc: 0.5381\n",
      "Epoch 5/1000\n",
      "8398/8398 - 2s - loss: 0.6906 - acc: 0.5381\n",
      "Epoch 6/1000\n",
      "8398/8398 - 2s - loss: 0.6905 - acc: 0.5381\n",
      "Epoch 7/1000\n",
      "8398/8398 - 2s - loss: 0.6906 - acc: 0.5381\n",
      "Epoch 8/1000\n",
      "8398/8398 - 2s - loss: 0.6905 - acc: 0.5381\n",
      "Epoch 9/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 10/1000\n",
      "8398/8398 - 2s - loss: 0.6903 - acc: 0.5381\n",
      "Epoch 11/1000\n",
      "8398/8398 - 1s - loss: 0.6905 - acc: 0.5381\n",
      "Epoch 12/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 13/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 14/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 15/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 16/1000\n",
      "8398/8398 - 2s - loss: 0.6905 - acc: 0.5381\n",
      "Epoch 17/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 18/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 19/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 20/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 21/1000\n",
      "8398/8398 - 1s - loss: 0.6902 - acc: 0.5381\n",
      "Epoch 22/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 23/1000\n",
      "8398/8398 - 2s - loss: 0.6903 - acc: 0.5381\n",
      "Epoch 24/1000\n",
      "8398/8398 - 2s - loss: 0.6903 - acc: 0.5381\n",
      "Epoch 25/1000\n",
      "8398/8398 - 2s - loss: 0.6905 - acc: 0.5381\n",
      "Epoch 26/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 27/1000\n",
      "8398/8398 - 2s - loss: 0.6903 - acc: 0.5381\n",
      "Epoch 28/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 29/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 30/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 31/1000\n",
      "8398/8398 - 2s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 32/1000\n",
      "8398/8398 - 1s - loss: 0.6903 - acc: 0.5381\n",
      "Epoch 33/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 34/1000\n",
      "8398/8398 - 1s - loss: 0.6904 - acc: 0.5381\n",
      "Epoch 35/1000\n"
     ]
    }
   ],
   "source": [
    "#Training the neurons\n",
    "\n",
    "model.fit(\n",
    "    input_df,\n",
    "    output_hot_shot_encoded,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict is what we use to see the neural net's output on real data\n",
    "results = model.predict(input_df, verbose=2)\n",
    "\n",
    "# This part basically will create an array with a bunch of [X,Y] inside.\n",
    "# Each [X,Y] pair represents the probability of the AI deciding to buy or sell on that day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to prove that the length of the results is equal to the length of the inputs. \n",
    "len(results) == len(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SANDBOXXXXXXXX\n",
    "df2 = df['BuyOrSell'].to_frame()\n",
    "\n",
    "# What the heck is the order of the results?\n",
    "# Lets split it up and try to find out how much sense it makes\n",
    "col1, col2 = zip(*results)\n",
    "\n",
    "\n",
    "# READ THIS PART LATER: \n",
    "# So the original sign was \">\" because it was assumed that the first column was the probability\n",
    "# to buy. So if X (the first col) was > than Y, the AI basically bought.\n",
    "# This is not true however, because it's backwards! The second column is whether or not it buys and the first\n",
    "# is sell. I believe this has to do with the way hot-encoding works and how a \n",
    "# 0 becomes a 1,0 while a 1 becomes a 0,1.\n",
    "# The sign has been switched to \"<\" and now it's finally correct\n",
    "def mapingFunc(x,y):\n",
    "    if x < y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# If the first col represents buy then when the first col's number is greater\n",
    "# than the second col's number, \n",
    "result = list(map(mapingFunc, col1, col2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SANDBOX STUFF. Messing around to try to find out exactly which number in the keras.predict means what\n",
    "\n",
    "df2['AIchoice'] = result\n",
    "df2.head(1)\n",
    "\n",
    "right_choice = 0\n",
    "wrong_choice = 0\n",
    "for index, row in df2.iterrows():\n",
    "    if row['BuyOrSell'] == row['AIchoice']:\n",
    "        right_choice += 1\n",
    "    else:\n",
    "        wrong_choice += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the total number of choices matches the inputDF. \n",
    "# This is good. No rows are missing\n",
    "right_choice + wrong_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what's the accuracy? It should be around 60% based on the verbose keras.fit\n",
    "right_choice / (right_choice + wrong_choice)\n",
    "# READ LATER: It was inverted and showing 40% accuracy. But since switching the signs, it is now correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_train_df = df2\n",
    "\n",
    "import ezmongo\n",
    "raw = ezmongo.get_data('GOOG', 'cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['BuyOrSell'] = df2['BuyOrSell']\n",
    "raw['AIchoice'] = df2['AIchoice']\n",
    "\n",
    "\n",
    "upload = {\"data\":raw.to_dict('records')}\n",
    "upload['id'] = 0\n",
    "upload['description'] = \"A standard feed forward NN that looked at today's high, low, open, closing, adjusted closing, and volumne and tried to use that data to predict tomorrow's price. It was trained on GOOG from 2004 to 2019 and even when ran on the same data, it only had 60% accuracy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezmongo.set_data(raw, 'GOOG','AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
