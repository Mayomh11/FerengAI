{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shhhhhhh......\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# Other imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from mongoDB\n",
    "import ezmongo\n",
    "df = ezmongo.get_data(\"GOOG\",\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I solating the columns we want.\n",
    "# Lets try all data points\n",
    "input_df = df.drop(['Date','BuyOrSell'], axis=1)\n",
    "\n",
    "output_df = df['BuyOrSell'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number_of_columns = len(input_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "# Even though the last columns is already 1 or 0, to_categorical needs to somehow convert this into \n",
    "# an array that looks like [x1,x2] and literally separate them into different states\n",
    "# Try printing out output and outputs_df to see the difference.\n",
    "output_hot_shot_encoded = to_categorical(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_hot_shot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the NN. Import the stuff\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/minglei/anaconda3/envs/PythonData/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#EDIT THIS SECTION OF CODE TO DESIGN YOUR OWN NEURAL NET.\n",
    "\n",
    "#Create the model\n",
    "model = Sequential()\n",
    "\n",
    "#Setting general NN info here\n",
    "\n",
    "number_of_inputs = len(input_df.columns)\n",
    "#We should have at least 1 extra layer. Just a design choice.\n",
    "number_of_layers = number_of_inputs + 1\n",
    "#Currently, the plan is to have an N by N grid system based on the number of inputs. \n",
    "number_of_neurons_per_layer = number_of_layers + 1\n",
    "\n",
    "\n",
    "#Adding the first input layer\n",
    "model.add(Dense(units=number_of_neurons_per_layer, activation='relu', input_dim=number_of_inputs))\n",
    "\n",
    "for i in range(number_of_layers):\n",
    "    model.add(Dense(units=number_of_neurons_per_layer, activation='relu'))\n",
    "\n",
    "#Adding the output layer\n",
    "model.add(Dense(units=2, activation='softmax')) \n",
    "#Compiling\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.327535</td>\n",
       "      <td>0.327535</td>\n",
       "      <td>0.341298</td>\n",
       "      <td>0.289089</td>\n",
       "      <td>0.276233</td>\n",
       "      <td>0.372115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adj Close     Close      High       Low      Open    Volume\n",
       "0   0.327535  0.327535  0.341298  0.289089  0.276233  0.372115"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One last look at what we're training the AI with\n",
    "input_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x112382c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the neurons\n",
    "\n",
    "model.fit(\n",
    "    input_df,\n",
    "    output_hot_shot_encoded,\n",
    "    epochs=100,\n",
    "    shuffle=False,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3775/3775 - 0s\n"
     ]
    }
   ],
   "source": [
    "# model.predict is what we use to see the neural net's output on real data\n",
    "results = model.predict(input_df, verbose=2)\n",
    "\n",
    "# This part basically will create an array with a bunch of [X,Y] inside.\n",
    "# Each [X,Y] pair represents the probability of the AI deciding to buy or sell on that day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to prove that the length of the results is equal to the length of the inputs. \n",
    "len(results) == len(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SANDBOXXXXXXXX\n",
    "df2 = df['BuyOrSell'].to_frame()\n",
    "\n",
    "# What the heck is the order of the results?\n",
    "# Lets split it up and try to find out how much sense it makes\n",
    "col1, col2 = zip(*results)\n",
    "\n",
    "\n",
    "# READ THIS PART LATER: \n",
    "# So the original sign was \">\" because it was assumed that the first column was the probability\n",
    "# to buy. So if X (the first col) was > than Y, the AI basically bought.\n",
    "# This is not true however, because it's backwards! The second column is whether or not it buys and the first\n",
    "# is sell. I believe this has to do with the way hot-encoding works and how a \n",
    "# 0 becomes a 1,0 while a 1 becomes a 0,1.\n",
    "# The sign has been switched to \"<\" and now it's finally correct\n",
    "def mapingFunc(x,y):\n",
    "    if x < y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# If the first col represents buy then when the first col's number is greater\n",
    "# than the second col's number, \n",
    "result = list(map(mapingFunc, col1, col2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SANDBOX STUFF. Messing around to try to find out exactly which number in the keras.predict means what\n",
    "\n",
    "df2['AIchoice'] = result\n",
    "df2.head(1)\n",
    "\n",
    "right_choice = 0\n",
    "wrong_choice = 0\n",
    "for index, row in df2.iterrows():\n",
    "    if row['BuyOrSell'] == row['AIchoice']:\n",
    "        right_choice += 1\n",
    "    else:\n",
    "        wrong_choice += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3775"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the total number of choices matches the inputDF. \n",
    "# This is good. No rows are missing\n",
    "right_choice + wrong_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593112582781457"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So what's the accuracy? It should be around 60% based on the verbose keras.fit\n",
    "right_choice / (right_choice + wrong_choice)\n",
    "# READ LATER: It was inverted and showing 40% accuracy. But since switching the signs, it is now correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_train_df = df2\n",
    "\n",
    "import ezmongo\n",
    "raw = ezmongo.get_data('GOOG', 'cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['BuyOrSell'] = df2['BuyOrSell']\n",
    "raw['AIchoice'] = df2['AIchoice']\n",
    "\n",
    "\n",
    "upload = {\"data\":raw.to_dict('records')}\n",
    "upload['id'] = 0\n",
    "upload['description'] = \"A standard feed forward NN that looked at today's high, low, open, closing, adjusted closing, and volumne and tried to use that data to predict tomorrow's price. It was trained on GOOG from 2004 to 2019 and even when ran on the same data, it only had 60% accuracy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezmongo.set_data(raw, 'GOOG','final_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
